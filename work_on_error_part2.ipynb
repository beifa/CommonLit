{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "work_on_error_part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17J2DO_8KGws4ekdgYcCx7iID9RUA1gUf",
      "authorship_tag": "ABX9TyPP/UrH64EgYMljvbhr6/Jz"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhqTeSQ9XezJ"
      },
      "source": [
        "## TODO\n",
        "\n",
        "https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-fit\n",
        "\n",
        "https://github.com/abhishekkrthakur/commonlit-pairwise-model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gok3_4IDoFKi"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Transformers разные слои захватывают разные уровни представлений. Они изучают богатую иерархию лингвистической информации, то есть с поверхностными функциями на нижних уровнях, синтаксическими функциями на средних уровнях и семантическими функциями на более высоких уровнях.\n",
        "\n",
        "<img src = 'http://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png'/>\n",
        "\n",
        "\n",
        "Авторы BERT протестировали стратегии встраивания слов, подавая различные комбинации векторов в качестве входных характеристик в BiLSTM, используемый в задаче распознавания именованных сущностей, и наблюдая за полученными баллами F1. Объединение последних четырех слоев дало наилучшие результаты.\n",
        "\n",
        "Частично это демонстрируется тем, что разные уровни BERT кодируют очень разные виды информации, поэтому соответствующая стратегия объединения будет меняться в зависимости от приложения, поскольку разные уровни кодируют разные виды информации. Это справедливо и для других вариантов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh4W8bL9H1NZ"
      },
      "source": [
        "from IPython.display import clear_output, Image\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3XwACKoH1Na",
        "outputId": "236a80c9-30eb-480a-ec13-1ad2096fd43f"
      },
      "source": [
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "import transformers\n",
        "\n",
        "path_tr = '/content/drive/MyDrive/CommonLit/input/train.csv'\n",
        "path_test = '/content/drive/MyDrive/CommonLit/input/test.csv'\n",
        "path_sub = '/content/drive/MyDrive/CommonLit/input/sample_submission.csv'\n",
        "\n",
        "SEED =13\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path='roberta-base')\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    pretrained_model_name_or_path='roberta-base',\n",
        "    num_labels=1)\n",
        "model = transformers.AutoModel.from_pretrained(\n",
        "    pretrained_model_name_or_path='roberta-base',\n",
        "    config=model_config)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixZxiKya04t2"
      },
      "source": [
        "df = pd.read_csv(path_tr)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J30G1kk67j8p"
      },
      "source": [
        "txt = df.excerpt[:6].values\n",
        "tkzr = tokenizer.batch_encode_plus(\n",
        "    list(txt), # batch_text_or_text_pairs has to be a list (got <class 'numpy.ndarray'>)\n",
        "    truncation=True,\n",
        "    max_length=256,\n",
        "    padding='max_length',\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    return_token_type_ids=False,\n",
        "    return_tensors='pt'\n",
        ")          "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzhc8o-T04qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48f04f7-0445-48f3-c3ef-0d449eac67a5"
      },
      "source": [
        "out = model(**tkzr)\n",
        "out"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[-0.0676,  0.0801,  0.0089,  ..., -0.0234, -0.0443, -0.0295],\n",
              "                                                        [-0.0136,  0.2424, -0.1040,  ..., -0.4047,  0.0952, -0.0992],\n",
              "                                                        [ 0.0357, -0.0299,  0.1018,  ..., -0.2944,  0.0626, -0.1154],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0610, -0.0185,  0.1139,  ...,  0.2247,  0.1071,  0.0041],\n",
              "                                                        [ 0.0610, -0.0185,  0.1139,  ...,  0.2247,  0.1071,  0.0041],\n",
              "                                                        [ 0.0610, -0.0185,  0.1139,  ...,  0.2247,  0.1071,  0.0041]],\n",
              "                                               \n",
              "                                                       [[-0.0829,  0.1356,  0.0139,  ..., -0.0217, -0.0603, -0.0491],\n",
              "                                                        [ 0.1458, -0.1178,  0.0553,  ...,  0.0597,  0.2168,  0.1527],\n",
              "                                                        [ 0.1772,  0.1132,  0.1627,  ..., -0.3505,  0.0937,  0.0639],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0302,  0.0683,  0.1068,  ...,  0.2405,  0.1002,  0.0403],\n",
              "                                                        [ 0.0302,  0.0683,  0.1068,  ...,  0.2405,  0.1002,  0.0403],\n",
              "                                                        [ 0.0302,  0.0683,  0.1068,  ...,  0.2405,  0.1002,  0.0403]],\n",
              "                                               \n",
              "                                                       [[-0.0928,  0.1262,  0.0197,  ..., -0.0684, -0.0534, -0.0382],\n",
              "                                                        [ 0.0978,  0.0350, -0.0059,  ..., -0.1911,  0.2294,  0.2469],\n",
              "                                                        [-0.0275, -0.0117, -0.0438,  ..., -0.2157, -0.1289,  0.1735],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0134,  0.0812,  0.1047,  ...,  0.2447,  0.0543,  0.0536],\n",
              "                                                        [ 0.0134,  0.0812,  0.1047,  ...,  0.2447,  0.0543,  0.0536],\n",
              "                                                        [ 0.0134,  0.0812,  0.1047,  ...,  0.2447,  0.0543,  0.0536]],\n",
              "                                               \n",
              "                                                       [[-0.0676,  0.0707, -0.0168,  ..., -0.0564, -0.0366, -0.0277],\n",
              "                                                        [-0.0998,  0.0409,  0.1070,  ..., -0.2781, -0.0188, -0.0868],\n",
              "                                                        [-0.0019, -0.1495, -0.0734,  ..., -0.4214,  0.1566, -0.0066],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0836, -0.0302,  0.0697,  ...,  0.1630,  0.1360, -0.0389],\n",
              "                                                        [ 0.0836, -0.0302,  0.0697,  ...,  0.1630,  0.1360, -0.0389],\n",
              "                                                        [ 0.0836, -0.0302,  0.0697,  ...,  0.1630,  0.1360, -0.0389]],\n",
              "                                               \n",
              "                                                       [[-0.0851,  0.0972, -0.0219,  ..., -0.0119, -0.0448, -0.0450],\n",
              "                                                        [-0.0640,  0.2848, -0.0854,  ...,  0.2070,  0.0708, -0.0217],\n",
              "                                                        [-0.2815,  0.3996, -0.0253,  ...,  0.5841,  0.3849,  0.0413],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0447,  0.0879,  0.0876,  ...,  0.2843,  0.0782,  0.0254],\n",
              "                                                        [ 0.0447,  0.0879,  0.0876,  ...,  0.2843,  0.0782,  0.0254],\n",
              "                                                        [ 0.0447,  0.0879,  0.0876,  ...,  0.2843,  0.0782,  0.0254]],\n",
              "                                               \n",
              "                                                       [[-0.1009,  0.0526,  0.0307,  ..., -0.0689, -0.0650, -0.0025],\n",
              "                                                        [ 0.1391, -0.0375,  0.0376,  ...,  0.2217, -0.0506,  0.0949],\n",
              "                                                        [-0.0375,  0.0333,  0.0535,  ...,  0.0425,  0.0796, -0.0839],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0580, -0.0541,  0.1173,  ...,  0.2462,  0.0887,  0.0702],\n",
              "                                                        [ 0.0580, -0.0541,  0.1173,  ...,  0.2462,  0.0887,  0.0702],\n",
              "                                                        [ 0.0580, -0.0541,  0.1173,  ...,  0.2462,  0.0887,  0.0702]]],\n",
              "                                                      grad_fn=<NativeLayerNormBackward>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[-0.0017, -0.2003, -0.1843,  ..., -0.1703, -0.0526, -0.1203],\n",
              "                                                       [-0.0234, -0.1960, -0.1675,  ..., -0.1891, -0.0479, -0.1147],\n",
              "                                                       [-0.0197, -0.1805, -0.1665,  ..., -0.1728, -0.0569, -0.1119],\n",
              "                                                       [-0.0109, -0.2007, -0.1587,  ..., -0.1813, -0.0479, -0.1344],\n",
              "                                                       [ 0.0098, -0.2013, -0.1894,  ..., -0.1752, -0.0564, -0.1424],\n",
              "                                                       [-0.0084, -0.2019, -0.1740,  ..., -0.2107, -0.0207, -0.1183]],\n",
              "                                                      grad_fn=<TanhBackward>))])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9pkETpua6nT"
      },
      "source": [
        "### pooler_output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3qCLVcZvf0X",
        "outputId": "6cda2fb4-b790-482c-b809-043b03a096ec"
      },
      "source": [
        "out['pooler_output'].shape, out['last_hidden_state'].shape, nn.Linear(768, 1)(out['pooler_output']).shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 768]), torch.Size([6, 256, 768]), torch.Size([6, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ClsPEVEbCCi"
      },
      "source": [
        "### last_hidden_state\n",
        "<img src = 'https://miro.medium.com/max/2120/1*p6PgpOV74U_qLrzr-1_4Zg.png'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qhX1kD4bYkl"
      },
      "source": [
        "#### CLS Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqFzExYwIdgG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}