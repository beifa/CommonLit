{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "work_on_error_part2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17J2DO_8KGws4ekdgYcCx7iID9RUA1gUf",
      "authorship_tag": "ABX9TyM4ZVt6C5F2DXHRcli/boHK"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhqTeSQ9XezJ"
      },
      "source": [
        "## TODO\n",
        "\n",
        "https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-fit\n",
        "\n",
        "https://github.com/abhishekkrthakur/commonlit-pairwise-model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gok3_4IDoFKi"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Transformers разные слои захватывают разные уровни представлений. Они изучают богатую иерархию лингвистической информации, то есть с поверхностными функциями на нижних уровнях, синтаксическими функциями на средних уровнях и семантическими функциями на более высоких уровнях.\n",
        "\n",
        "<img src = 'http://jalammar.github.io/images/bert-feature-extraction-contextualized-embeddings.png'/>\n",
        "\n",
        "\n",
        "Авторы BERT протестировали стратегии встраивания слов, подавая различные комбинации векторов в качестве входных характеристик в BiLSTM, используемый в задаче распознавания именованных сущностей, и наблюдая за полученными баллами F1. Объединение последних четырех слоев дало наилучшие результаты.\n",
        "\n",
        "Частично это демонстрируется тем, что разные уровни BERT кодируют очень разные виды информации, поэтому соответствующая стратегия объединения будет меняться в зависимости от приложения, поскольку разные уровни кодируют разные виды информации. Это справедливо и для других вариантов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh4W8bL9H1NZ"
      },
      "source": [
        "from IPython.display import clear_output, Image\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3XwACKoH1Na",
        "outputId": "236a80c9-30eb-480a-ec13-1ad2096fd43f"
      },
      "source": [
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "import transformers\n",
        "\n",
        "path_tr = '/content/drive/MyDrive/CommonLit/input/train.csv'\n",
        "path_test = '/content/drive/MyDrive/CommonLit/input/test.csv'\n",
        "path_sub = '/content/drive/MyDrive/CommonLit/input/sample_submission.csv'\n",
        "\n",
        "SEED =13\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    pretrained_model_name_or_path='roberta-base')\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    pretrained_model_name_or_path='roberta-base',\n",
        "    num_labels=1)\n",
        "model = transformers.AutoModel.from_pretrained(\n",
        "    pretrained_model_name_or_path='roberta-base',\n",
        "    config=model_config)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixZxiKya04t2"
      },
      "source": [
        "df = pd.read_csv(path_tr)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J30G1kk67j8p"
      },
      "source": [
        "txt = df.excerpt[:6].values\n",
        "tkzr = tokenizer.batch_encode_plus(\n",
        "    list(txt), # batch_text_or_text_pairs has to be a list (got <class 'numpy.ndarray'>)\n",
        "    truncation=True,\n",
        "    max_length=256,\n",
        "    padding='max_length',\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    return_token_type_ids=False,\n",
        "    return_tensors='pt'\n",
        ")          "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzhc8o-T04qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695c3548-3dca-4dc1-f4fc-f7265eb1eccf"
      },
      "source": [
        "out = model(**tkzr)\n",
        "out"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[-0.0676,  0.0801,  0.0089,  ..., -0.0234, -0.0443, -0.0295],\n",
              "                                                        [-0.0136,  0.2424, -0.1040,  ..., -0.4047,  0.0952, -0.0992],\n",
              "                                                        [ 0.0357, -0.0299,  0.1018,  ..., -0.2944,  0.0626, -0.1154],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0610, -0.0185,  0.1139,  ...,  0.2247,  0.1071,  0.0041],\n",
              "                                                        [ 0.0610, -0.0185,  0.1139,  ...,  0.2247,  0.1071,  0.0041],\n",
              "                                                        [ 0.0610, -0.0185,  0.1139,  ...,  0.2247,  0.1071,  0.0041]],\n",
              "                                               \n",
              "                                                       [[-0.0829,  0.1356,  0.0139,  ..., -0.0217, -0.0603, -0.0491],\n",
              "                                                        [ 0.1458, -0.1178,  0.0553,  ...,  0.0597,  0.2168,  0.1527],\n",
              "                                                        [ 0.1772,  0.1132,  0.1627,  ..., -0.3505,  0.0937,  0.0639],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0302,  0.0683,  0.1068,  ...,  0.2405,  0.1002,  0.0403],\n",
              "                                                        [ 0.0302,  0.0683,  0.1068,  ...,  0.2405,  0.1002,  0.0403],\n",
              "                                                        [ 0.0302,  0.0683,  0.1068,  ...,  0.2405,  0.1002,  0.0403]],\n",
              "                                               \n",
              "                                                       [[-0.0928,  0.1262,  0.0197,  ..., -0.0684, -0.0534, -0.0382],\n",
              "                                                        [ 0.0978,  0.0350, -0.0059,  ..., -0.1911,  0.2294,  0.2469],\n",
              "                                                        [-0.0275, -0.0117, -0.0438,  ..., -0.2157, -0.1289,  0.1735],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0134,  0.0812,  0.1047,  ...,  0.2447,  0.0543,  0.0536],\n",
              "                                                        [ 0.0134,  0.0812,  0.1047,  ...,  0.2447,  0.0543,  0.0536],\n",
              "                                                        [ 0.0134,  0.0812,  0.1047,  ...,  0.2447,  0.0543,  0.0536]],\n",
              "                                               \n",
              "                                                       [[-0.0676,  0.0707, -0.0168,  ..., -0.0564, -0.0366, -0.0277],\n",
              "                                                        [-0.0998,  0.0409,  0.1070,  ..., -0.2781, -0.0188, -0.0868],\n",
              "                                                        [-0.0019, -0.1495, -0.0734,  ..., -0.4214,  0.1566, -0.0066],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0836, -0.0302,  0.0697,  ...,  0.1630,  0.1360, -0.0389],\n",
              "                                                        [ 0.0836, -0.0302,  0.0697,  ...,  0.1630,  0.1360, -0.0389],\n",
              "                                                        [ 0.0836, -0.0302,  0.0697,  ...,  0.1630,  0.1360, -0.0389]],\n",
              "                                               \n",
              "                                                       [[-0.0851,  0.0972, -0.0219,  ..., -0.0119, -0.0448, -0.0450],\n",
              "                                                        [-0.0640,  0.2848, -0.0854,  ...,  0.2070,  0.0708, -0.0217],\n",
              "                                                        [-0.2815,  0.3996, -0.0253,  ...,  0.5841,  0.3849,  0.0413],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0447,  0.0879,  0.0876,  ...,  0.2843,  0.0782,  0.0254],\n",
              "                                                        [ 0.0447,  0.0879,  0.0876,  ...,  0.2843,  0.0782,  0.0254],\n",
              "                                                        [ 0.0447,  0.0879,  0.0876,  ...,  0.2843,  0.0782,  0.0254]],\n",
              "                                               \n",
              "                                                       [[-0.1009,  0.0526,  0.0307,  ..., -0.0689, -0.0650, -0.0025],\n",
              "                                                        [ 0.1391, -0.0375,  0.0376,  ...,  0.2217, -0.0506,  0.0949],\n",
              "                                                        [-0.0375,  0.0333,  0.0535,  ...,  0.0425,  0.0796, -0.0839],\n",
              "                                                        ...,\n",
              "                                                        [ 0.0580, -0.0541,  0.1173,  ...,  0.2462,  0.0887,  0.0702],\n",
              "                                                        [ 0.0580, -0.0541,  0.1173,  ...,  0.2462,  0.0887,  0.0702],\n",
              "                                                        [ 0.0580, -0.0541,  0.1173,  ...,  0.2462,  0.0887,  0.0702]]],\n",
              "                                                      grad_fn=<NativeLayerNormBackward>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[-0.0017, -0.2003, -0.1843,  ..., -0.1703, -0.0526, -0.1203],\n",
              "                                                       [-0.0234, -0.1960, -0.1675,  ..., -0.1891, -0.0479, -0.1147],\n",
              "                                                       [-0.0197, -0.1805, -0.1665,  ..., -0.1728, -0.0569, -0.1119],\n",
              "                                                       [-0.0109, -0.2007, -0.1587,  ..., -0.1813, -0.0479, -0.1344],\n",
              "                                                       [ 0.0098, -0.2013, -0.1894,  ..., -0.1752, -0.0564, -0.1424],\n",
              "                                                       [-0.0084, -0.2019, -0.1740,  ..., -0.2107, -0.0207, -0.1183]],\n",
              "                                                      grad_fn=<TanhBackward>))])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9pkETpua6nT"
      },
      "source": [
        "### pooler_output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3qCLVcZvf0X",
        "outputId": "6cda2fb4-b790-482c-b809-043b03a096ec"
      },
      "source": [
        "out['pooler_output'].shape, out['last_hidden_state'].shape, nn.Linear(768, 1)(out['pooler_output']).shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([6, 768]), torch.Size([6, 256, 768]), torch.Size([6, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP7pZfmDd1bP",
        "outputId": "9a9a9dfd-2e03-4076-f82c-d02837729b96"
      },
      "source": [
        "reg_head = nn.Linear(768, 1)(out['pooler_output'])\n",
        "reg_head"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0772],\n",
              "        [0.0678],\n",
              "        [0.0837],\n",
              "        [0.0888],\n",
              "        [0.0915],\n",
              "        [0.0879]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ClsPEVEbCCi"
      },
      "source": [
        "### last_hidden_state\n",
        "<img src = 'https://miro.medium.com/max/2120/1*p6PgpOV74U_qLrzr-1_4Zg.png'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qhX1kD4bYkl"
      },
      "source": [
        "#### CLS Embeddings\n",
        "\n",
        "Поскольку преобразователи представляют собой контекстную модель, идея состоит в том, что токен [CLS] захватил бы весь контекст и был бы достаточен для простых последующих задач, таких как классификация."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqFzExYwIdgG",
        "outputId": "1de07d9c-42f7-495e-c52c-4f9e50f3c315"
      },
      "source": [
        "out['last_hidden_state'][:, 0].shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80HG6X8zeD9f",
        "outputId": "0840c2f7-2fd6-4d95-d875-fd1ac46495e3"
      },
      "source": [
        "reg_head_clstoken_embeddings = nn.Linear(768, 1)(out['last_hidden_state'][:, 0])\n",
        "reg_head_clstoken_embeddings "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3017],\n",
              "        [-0.3277],\n",
              "        [-0.2973],\n",
              "        [-0.3019],\n",
              "        [-0.3124],\n",
              "        [-0.3453]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7ie1U0DhJcu"
      },
      "source": [
        "#### Mean Pooling\n",
        "\n",
        "- Step 1: Expand Attention Mask from [batch_size, max_len] to [batch_size, max_len, hidden_size].\n",
        "- Step 2: Sum Embeddings along max_len axis so now we have [batch_size, hidden_size].\n",
        "- Step 3: Sum Mask along max_len axis. This is done so that we can ignore padding tokens.\n",
        "- Step 4: Take Average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qUovztseTEy",
        "outputId": "18c107fe-dbe8-4623-92c2-d1435ea02e20"
      },
      "source": [
        "\"\"\"\n",
        "torch.Size([6, 256])\n",
        "unsqueeze\n",
        ">> torch.Size([6, 256, 1])\n",
        "expand we set size . expand(size) and expand for larger size\n",
        ".epand(6, 256, 768) and expand 768 if set -1 no change size\n",
        ".epand(-1, -1, 768) get  (6, 256, 768)\n",
        "\n",
        "nullify unnecessary(by mask where zeros)\n",
        "out['last_hidden_state'] * att_mask_exp\n",
        ".sum\n",
        ">> torch.Size([6, 768])\n",
        "next we get sum by len\n",
        ".clamp set values in range\n",
        "and find mean\n",
        ">> torch.Size([6, 768])\n",
        "\"\"\"\n",
        "att_mask_exp = tkzr['attention_mask'].unsqueeze(-1).expand(out['last_hidden_state'].size()).float()\n",
        "sum_embeddings = torch.sum(out['last_hidden_state'] * att_mask_exp, 1)\n",
        "sum_mask  = att_mask_exp.sum(1)\n",
        "sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "mean_embeddings = sum_embeddings / sum_mask\n",
        "mean_embeddings.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg4beAX5lS26",
        "outputId": "e99e0f11-7b6a-44b7-e08a-4f65e7a2ac89"
      },
      "source": [
        "nn.Linear(768, 1)(mean_embeddings)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0307],\n",
              "        [-0.0165],\n",
              "        [ 0.0086],\n",
              "        [ 0.0197],\n",
              "        [ 0.0041],\n",
              "        [-0.0188]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r6u87-_5NPl"
      },
      "source": [
        "#### Max Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq52gsOH3SA3",
        "outputId": "6a777f28-0904-48a9-f6a7-892bf92cd7e4"
      },
      "source": [
        "att_mask_exp = tkzr['attention_mask'].unsqueeze(-1).expand(out['last_hidden_state'].size()).float()\n",
        "# Set padding tokens to large negative value\n",
        "out['last_hidden_state'][att_mask_exp == 0] = -1e9\n",
        "max_embeddings = torch.max(out['last_hidden_state'], 1)[0]\n",
        "nn.Linear(768, 1)(max_embeddings)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4185],\n",
              "        [-0.2180],\n",
              "        [-0.2681],\n",
              "        [-0.3354],\n",
              "        [-0.2616],\n",
              "        [-0.4914]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoHW18S4CcVF"
      },
      "source": [
        "#### Mean-Max Pooling (Head)\n",
        "<img src= 'https://media.springernature.com/original/springer-static/image/chp%3A10.1007%2F978-3-030-58323-1_23/MediaObjects/498432_1_En_23_Fig1_HTML.png'/>\n",
        "\n",
        "Сначала мы находим вложения среднего и максимального пула, а затем объединяем их, чтобы получить окончательное представление, которое вдвое превышает скрытый размер."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ-54oF16UKB",
        "outputId": "f14a762b-63e7-4370-ea2f-6e2f76aeef38"
      },
      "source": [
        "# var1\n",
        "mean_embeddings = torch.mean(out['last_hidden_state'], 1)\n",
        "_, max_embeddings = torch.max(out['last_hidden_state'], 1)\n",
        "mean_max_embeddings = torch.cat((mean_embeddings, max_embeddings), 1)\n",
        "nn.Linear(768 * 2, 1)(mean_max_embeddings)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  1.9549],\n",
              "        [ 58.3857],\n",
              "        [-20.5326],\n",
              "        [-12.3191],\n",
              "        [ -5.8741],\n",
              "        [ 55.0666]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14hJkVAPF4Se",
        "outputId": "3aef4ad5-ce80-49b8-f2f7-351e7c005db3"
      },
      "source": [
        "# var2\n",
        "mean_max_embeddings = torch.cat((max_embeddings, mean_embeddings), 1)\n",
        "nn.Linear(768 * 2, 1)(mean_max_embeddings)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2407],\n",
              "        [-0.3398],\n",
              "        [-0.3508],\n",
              "        [-0.3531],\n",
              "        [-0.2457],\n",
              "        [-0.3942]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ]
}