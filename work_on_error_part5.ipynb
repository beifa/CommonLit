{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "work_on_error_part5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1e4GKfnEM5LpAfnDsfDWkHwU0BkZZbWlD",
      "authorship_tag": "ABX9TyNNf8pygnYGTPrnbewsuUZm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgudlyKuktQ-"
      },
      "source": [
        "TODO\n",
        "\n",
        "[kaggle 22 place solution]('https://www.kaggle.com/c/commonlitreadabilityprize/discussion/257302)\n",
        "\n",
        "[github]('https://github.com/kurupical/commonlit)\n",
        "\n",
        "[inference]('https://www.kaggle.com/kurupical/191-192-202-228-251-253-268-288-278-final?scriptVersionId=69642056)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utm-JHn_UwEu"
      },
      "source": [
        "## Description\n",
        "\n",
        "### worked for me\n",
        "- model ensemble: I thought diversity is the most important thing in this competition.\n",
        "    - At the beginning of the competition, I tested the effectiveness of the ensemble.\n",
        "    - Up to the middle stage, I fixed the model to roberta-large and tried to improve the score.\n",
        "    - At the end, I applied the method to another models. I found that key parameters for this task are {learning_rate, N layers to re-initialize}, so I tuned those parameters for each models.\n",
        "- re-initialization\n",
        "    - This paper (https://arxiv.org/pdf/2006.05987.pdf) shows that fine-tuning with reinitialization last N layers works well.\n",
        "    - Different models have different optimal N. Almost models set N=4~5, gpt2-models set N=6.\n",
        "- LSTM head\n",
        "    - Input BERT's first and last hidden layer into LSTM layer worked well.\n",
        "    - I think first layer represent vocabulary difficulty and last layer represent sentence difficulty. Both are important for inference readbility.\n",
        "- Remove dropout. Improve 0.01~0.02 CV.\n",
        "- gradient clipping. (0.2 or 0.5 works well for me, improve about 0.005 CV)\n",
        "\n",
        "### not worked for me\n",
        "- Input attention matrix to 2D-CNN(like ResNet18 or simple 2DCNN)\n",
        "    - I thought this could represent the complexity of sentences with relative pronouns.\n",
        "- masked 5%~10% vocabulary.\n",
        "- Minimize KLDiv loss to fit distribution.\n",
        "- Scale target to 0~1 and minimize crossentropy loss\n",
        "- \"base\" models excluding mpnet. I got 0.47x CV but Public LB: 0.48x ~ 0.49x.\n",
        "- Stacking using LightGBM.\n",
        "- another models.(result is below table. single CV is well but zero weight for ensemble)\n",
        "- T5. Below notebook achieve 0.47 LB using T5, so I tried but failed.\n",
        "I got only 0.49x(fold 0 only) with learning_rate=1.5e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjh2wZULST-c"
      },
      "source": [
        "configuration for almost all models:\n",
        "```\n",
        "epochs = 4\n",
        "optimizer: AdamW\n",
        "scheduler: linear_schedule_with_warmup(warmup: 5%)\n",
        "lr_bert: 3e-5\n",
        "batch_size: 12\n",
        "gradient clipping: 0.2~0.5\n",
        "reinitialize layers: last 2~6 layers\n",
        "ensemble: Nelder-Mead\n",
        "custom head(finally concat all)\n",
        "    averaging last 4 hidden layer\n",
        "    LSTM head\n",
        "    vocabulary dense\n",
        "hidden_states: (batch_size, vocab_size, bert_hidden_size)\n",
        "  linear_vocab = nn.Sequential(\n",
        "      nn.Linear(bert_hidden_size, 128),\n",
        "      nn.GELU(),\n",
        "      nn.Linear(128, 64),\n",
        "      nn.GELU()\n",
        "  )\n",
        "  linear_final = nn.Linear(vocab_size * 64, 128)\n",
        "  out = linear_vocab(hidden_states).view(len(input_ids), -1)) # final shape: (batch_size, vocab_size * 64)\n",
        "  out = linear_final(out) # out shape: (batch_size, 128)\n",
        "17 hand-made features\n",
        "    sentence count\n",
        "    average character count in documents\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUpoxLVGWSdY"
      },
      "source": [
        "The main hyperparameters:\n",
        "\n",
        "|nlp_model_name|funnel-large-base|funnel-large|\n",
        "|----|----|----|\n",
        "|dropout|\t0|\t0|\n",
        "batch_size|\t12|\t12|\n",
        "lr_bert|\t2E-05|\t2E-05|\n",
        "lr_fc|\t5E-05|\t5E-05|\n",
        "warmup_ratio|\t0.05|\t0.05|\n",
        "epochs|\t6|\t6|\n",
        "activation|\tGELU|\tGELU|\n",
        "optimizer|\tAdamW|\tAdamW|\n",
        "weight_decay|\t0.1|\t0.1|\n",
        "rnn_module|\tLSTM|\tLSTM|\n",
        "rnn_module_num|\t0|\t1|\n",
        "rnn_hidden_indice|\t(-1, 0)|\t(-1, 0)|\n",
        "linear_vocab_enable|\tFalse|\tTrue|\n",
        "multi_dropout_ratio|\t0.3|\t0.3|\n",
        "multi_dropout_num|\t10|\t10|\n",
        "max_length|\t256|\t256|\n",
        "hidden_stack_enable|\tTrue|\tTrue|\n",
        "reinit_layers|\t4|\t4|\n",
        "gradient_clipping|\t0.2|\t0.2|\n",
        "feature_enable|\tFalse|\tTrue|\n",
        "stochastic_weight_avg|\tFalse|\tFalse|\n",
        "val_check_interval|\t0.05|\t0.05|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh4W8bL9H1NZ"
      },
      "source": [
        "from IPython.display import clear_output, Image\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VrF0HxynKym"
      },
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "# !sudo update-alternatives --config python3\n",
        "clear_output()\n",
        "!python --version"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3XwACKoH1Na"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import itertools\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from numpy import random\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\"\"\"\n",
        "any:Это означает, что можно выполнить любую операцию или вызов метода \n",
        "    для значения типа Any и присвоить его любой переменной\n",
        "\n",
        "optional: Обратите внимание, что это не то же самое, что необязательный\n",
        "          аргумент, который имеет значение по умолчанию.\n",
        "\"\"\"\n",
        "from typing import Any, Optional, List, Tuple\n",
        "\n",
        "\"\"\"\n",
        "получения информации о запущенных процессах\n",
        "и использовании системы (ЦП, память, диски, сеть, датчики) в Python.\n",
        "\"\"\"\n",
        "import psutil\n",
        "\n",
        "path_tr = '/content/drive/MyDrive/CommonLit/input/train.csv'\n",
        "path_test = '/content/drive/MyDrive/CommonLit/input/test.csv'\n",
        "path_sub = '/content/drive/MyDrive/CommonLit/input/sample_submission.csv'\n",
        "\n",
        "SEED =13\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dIZ7PS2kV6r"
      },
      "source": [
        "## dataclass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siMBoJn2Rwvn"
      },
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    experiment_name: str\n",
        "    seed: int = 10\n",
        "    debug: bool = False\n",
        "    fold: int = 0\n",
        "\n",
        "    nlp_model_name: str = \"roberta-base\"\n",
        "    linear_dim: int = 64\n",
        "    linear_vocab_dim_1: int = 64\n",
        "    linear_vocab_dim: int = 16\n",
        "    linear_perplexity_dim: int = 64\n",
        "    linear_final_dim: int = 256\n",
        "    dropout: float = 0\n",
        "    dropout_stack: float = 0\n",
        "    dropout_output_hidden: float = 0\n",
        "    dropout_attn: float = 0\n",
        "    batch_size: int = 32\n",
        "\n",
        "    lr_bert: float = 3e-5\n",
        "    lr_fc: float = 5e-5\n",
        "    lr_rnn: float = 1e-3\n",
        "    lr_tcn: float = 1e-3\n",
        "    lr_cnn: float = 1e-3\n",
        "    warmup_ratio: float = 0.1\n",
        "    training_steps_ratio: float = 1\n",
        "    if debug:\n",
        "        epochs: int = 2\n",
        "        epochs_max: int = 8\n",
        "    else:\n",
        "        epochs: int = 6\n",
        "        epochs_max: int = 6\n",
        "\n",
        "    activation: Any = nn.GELU\n",
        "    # optimizer: Any = transformers.AdamW\n",
        "    weight_decay: float = 0.1\n",
        "\n",
        "    rnn_module: nn.Module = nn.LSTM\n",
        "    rnn_module_num: int = 0\n",
        "    rnn_module_dropout: float = 0\n",
        "    rnn_module_activation: Any = None\n",
        "    rnn_module_shrink_ratio: float = 0.25\n",
        "    rnn_hidden_indice: Tuple[int] = (-1, 0)\n",
        "    bidirectional: bool = True\n",
        "\n",
        "    tcn_module_enable: bool = False\n",
        "    tcn_module_num: int = 3\n",
        "    # tcn_module: nn.Module = TemporalConvNet\n",
        "    tcn_module_kernel_size: int = 4\n",
        "    tcn_module_dropout: float = 0\n",
        "\n",
        "    linear_vocab_enable: bool = False\n",
        "    augmantation_range: Tuple[float, float] = (0, 0)\n",
        "    lr_bert_decay: float = 1\n",
        "\n",
        "    multi_dropout_ratio: float = 0.3\n",
        "    multi_dropout_num: int = 10\n",
        "    fine_tuned_path: str = None\n",
        "\n",
        "    # convnet\n",
        "    cnn_model_name: str = \"resnet18\"\n",
        "    cnn_pretrained: bool = False\n",
        "    self_attention_enable: bool = False\n",
        "\n",
        "    mask_p: float = 0\n",
        "    max_length: int = 256\n",
        "\n",
        "    hidden_stack_enable: bool = False\n",
        "    prep_enable: bool = False\n",
        "    kl_div_enable: bool = False\n",
        "\n",
        "    # reinit\n",
        "    reinit_pooler: bool = True\n",
        "    reinit_layers: int = 4\n",
        "\n",
        "    # pooler\n",
        "    pooler_enable: bool = True\n",
        "\n",
        "    word_axis: bool = False\n",
        "\n",
        "    # conv1d\n",
        "    conv1d_num: int = 1\n",
        "    conv1d_stride: int = 2\n",
        "    conv1d_kernel_size: int = 2\n",
        "\n",
        "    attention_pool_enable: bool = False\n",
        "    conv2d_hidden_channel: int = 32\n",
        "\n",
        "    simple_structure: bool = False\n",
        "    crossentropy: bool = False\n",
        "    crossentropy_min: int = -8\n",
        "    crossentropy_max: int = 4\n",
        "\n",
        "    accumulate_grad_batches: int = 1\n",
        "    gradient_clipping: int = 0.2\n",
        "\n",
        "    dropout_bert: float = 0\n",
        "\n",
        "    feature_enable: bool = False\n",
        "    decoder_only: bool = True\n",
        "\n",
        "    stochastic_weight_avg: bool = False\n",
        "    val_check_interval: float = 0.05\n",
        "\n",
        "    attention_head_enable: bool = False\n",
        "\n",
        "cfg = Config('test1')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB2tWMiZqz8b",
        "outputId": "ed327e03-e761-44ec-86bd-c9dced16ceec"
      },
      "source": [
        "cfg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Config(experiment_name='test1', seed=10, debug=False, fold=0, nlp_model_name='roberta-base', linear_dim=64, linear_vocab_dim_1=64, linear_vocab_dim=16, linear_perplexity_dim=64, linear_final_dim=256, dropout=0, dropout_stack=0, dropout_output_hidden=0, dropout_attn=0, batch_size=32, lr_bert=3e-05, lr_fc=5e-05, lr_rnn=0.001, lr_tcn=0.001, lr_cnn=0.001, warmup_ratio=0.1, training_steps_ratio=1, epochs=6, epochs_max=6, activation=<class 'torch.nn.modules.activation.GELU'>, weight_decay=0.1, rnn_module=<class 'torch.nn.modules.rnn.LSTM'>, rnn_module_num=0, rnn_module_dropout=0, rnn_module_activation=None, rnn_module_shrink_ratio=0.25, rnn_hidden_indice=(-1, 0), bidirectional=True, tcn_module_enable=False, tcn_module_num=3, tcn_module_kernel_size=4, tcn_module_dropout=0, linear_vocab_enable=False, augmantation_range=(0, 0), lr_bert_decay=1, multi_dropout_ratio=0.3, multi_dropout_num=10, fine_tuned_path=None, cnn_model_name='resnet18', cnn_pretrained=False, self_attention_enable=False, mask_p=0, max_length=256, hidden_stack_enable=False, prep_enable=False, kl_div_enable=False, reinit_pooler=True, reinit_layers=4, pooler_enable=True, word_axis=False, conv1d_num=1, conv1d_stride=2, conv1d_kernel_size=2, attention_pool_enable=False, conv2d_hidden_channel=32, simple_structure=False, crossentropy=False, crossentropy_min=-8, crossentropy_max=4, accumulate_grad_batches=1, gradient_clipping=0.2, dropout_bert=0, feature_enable=False, decoder_only=True, stochastic_weight_avg=False, val_check_interval=0.05, attention_head_enable=False)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBILdlwBdOPm"
      },
      "source": [
        "## feature_engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTrjgerCRws9"
      },
      "source": [
        "def total_words(x):\n",
        "    return len(x.split(\" \"))\n",
        "\n",
        "def total_unique_words(x):\n",
        "    return len(np.unique(x.split(\" \")))\n",
        "\n",
        "def total_charactors(x):\n",
        "    x = x.replace(\" \", \"\")\n",
        "    return len(x)\n",
        "\n",
        "def total_sentence(x):\n",
        "    x = x.replace(\"!\", \"[end]\").replace(\"?\", \"[end]\").replace(\".\", \"[end]\")\n",
        "    return len(x.split(\"[end]\"))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BZCpAshjVZh",
        "outputId": "ac216fa6-0f4e-4c20-9869-60af48131d33"
      },
      "source": [
        "df = pd.read_csv(path_tr)\n",
        "df.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'url_legal', 'license', 'excerpt', 'target', 'standard_error'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "xkF1AzqIjZZG",
        "outputId": "c7dc6144-9f70-482d-d9dc-4af4ee2590d6"
      },
      "source": [
        "df_ret = df[[\"id\", \"excerpt\", \"target\", \"standard_error\"]]\n",
        "excerpt = df[\"excerpt\"].values\n",
        "df_ret[\"total_words\"] = [total_words(x) for x in excerpt]\n",
        "df_ret[\"total_unique_words\"] = [total_unique_words(x) for x in excerpt]\n",
        "df_ret[\"total_characters\"] = [total_charactors(x) for x in excerpt]\n",
        "df_ret[\"total_sentence\"] = [total_sentence(x) for x in excerpt]\n",
        "\n",
        "df_ret[\"div_sentence_characters\"] = df_ret[\"total_sentence\"] / df_ret[\"total_characters\"]\n",
        "df_ret[\"div_sentence_words\"] = df_ret[\"total_sentence\"] / df_ret[\"total_words\"]\n",
        "df_ret[\"div_characters_words\"] = df_ret[\"total_characters\"] / df_ret[\"total_words\"]\n",
        "df_ret[\"div_words_unique_words\"] = df_ret[\"total_words\"] / df_ret[\"total_unique_words\"]\n",
        "\n",
        "for i, word in enumerate([\"!\", \"?\", \"(\", \")\", \"'\", '\"', \";\", \".\", \",\"]):\n",
        "    df_ret[f\"count_word_special_{i}\"] = [x.count(word) for x in excerpt]\n",
        "df_ret.fillna(0, inplace=True)\n",
        "\n",
        "df_ret.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "      <th>total_words</th>\n",
              "      <th>total_unique_words</th>\n",
              "      <th>total_characters</th>\n",
              "      <th>total_sentence</th>\n",
              "      <th>div_sentence_characters</th>\n",
              "      <th>div_sentence_words</th>\n",
              "      <th>div_characters_words</th>\n",
              "      <th>div_words_unique_words</th>\n",
              "      <th>count_word_special_0</th>\n",
              "      <th>count_word_special_1</th>\n",
              "      <th>count_word_special_2</th>\n",
              "      <th>count_word_special_3</th>\n",
              "      <th>count_word_special_4</th>\n",
              "      <th>count_word_special_5</th>\n",
              "      <th>count_word_special_6</th>\n",
              "      <th>count_word_special_7</th>\n",
              "      <th>count_word_special_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "      <td>174</td>\n",
              "      <td>112</td>\n",
              "      <td>819</td>\n",
              "      <td>12</td>\n",
              "      <td>0.014652</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>4.706897</td>\n",
              "      <td>1.553571</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "      <td>164</td>\n",
              "      <td>123</td>\n",
              "      <td>774</td>\n",
              "      <td>18</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.109756</td>\n",
              "      <td>4.719512</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b69ac6792</td>\n",
              "      <td>As Roger had predicted, the snow departed as q...</td>\n",
              "      <td>-0.580118</td>\n",
              "      <td>0.476676</td>\n",
              "      <td>162</td>\n",
              "      <td>124</td>\n",
              "      <td>747</td>\n",
              "      <td>13</td>\n",
              "      <td>0.017403</td>\n",
              "      <td>0.080247</td>\n",
              "      <td>4.611111</td>\n",
              "      <td>1.306452</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dd1000b26</td>\n",
              "      <td>And outside before the palace a great garden w...</td>\n",
              "      <td>-1.054013</td>\n",
              "      <td>0.450007</td>\n",
              "      <td>163</td>\n",
              "      <td>117</td>\n",
              "      <td>747</td>\n",
              "      <td>6</td>\n",
              "      <td>0.008032</td>\n",
              "      <td>0.036810</td>\n",
              "      <td>4.582822</td>\n",
              "      <td>1.393162</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37c1b32fb</td>\n",
              "      <td>Once upon a time there were Three Bears who li...</td>\n",
              "      <td>0.247197</td>\n",
              "      <td>0.510845</td>\n",
              "      <td>147</td>\n",
              "      <td>51</td>\n",
              "      <td>577</td>\n",
              "      <td>6</td>\n",
              "      <td>0.010399</td>\n",
              "      <td>0.040816</td>\n",
              "      <td>3.925170</td>\n",
              "      <td>2.882353</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ... count_word_special_8\n",
              "0  c12129c31  ...                   14\n",
              "1  85aa80a4c  ...                   24\n",
              "2  b69ac6792  ...                   17\n",
              "3  dd1000b26  ...                   23\n",
              "4  37c1b32fb  ...                   13\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urhIgnksJyKT",
        "outputId": "ee7ad7f9-08ef-4988-d185-da8a0d3cd670"
      },
      "source": [
        "cfg.feature_columns = [x for x in df_ret.columns if x not in [\"id\", \"excerpt\", \"target\", \"kfold\", \"standard_error\"]]\n",
        "\"\"\"\n",
        ".mean\n",
        "    array([1.71654905e+02, 1.13895554e+02, 8.01077982e+02, 1.08479181e+01,\n",
        "        1.37249582e-02, 6.32846225e-02, 4.66937398e+00, 1.51519104e+00,\n",
        "        4.57304164e-01, 3.55681016e-01, 3.68031052e-01, 3.68031052e-01,\n",
        "        1.15031757e+00, 2.38884968e+00, 8.71912491e-01, 9.03493296e+00,\n",
        "        1.17314749e+01])\n",
        "\"\"\"\n",
        "cfg.feature_mean = df_ret[cfg.feature_columns].mean().values\n",
        "cfg.feature_std = df_ret[cfg.feature_columns].std().values\n",
        "cfg.feature_columns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['total_words',\n",
              " 'total_unique_words',\n",
              " 'total_characters',\n",
              " 'total_sentence',\n",
              " 'div_sentence_characters',\n",
              " 'div_sentence_words',\n",
              " 'div_characters_words',\n",
              " 'div_words_unique_words',\n",
              " 'count_word_special_0',\n",
              " 'count_word_special_1',\n",
              " 'count_word_special_2',\n",
              " 'count_word_special_3',\n",
              " 'count_word_special_4',\n",
              " 'count_word_special_5',\n",
              " 'count_word_special_6',\n",
              " 'count_word_special_7',\n",
              " 'count_word_special_8']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySUBNgrUXAhV"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7Bjwo3CRQ96"
      },
      "source": [
        "class CommonLitDataset(Dataset):\n",
        "    \"\"\"   \n",
        "    return:\n",
        "        input_ids_masked\n",
        "        attention_mask\n",
        "        token_type_ids\n",
        "        input_ids\n",
        "\n",
        "        features - array norm maked features\n",
        "        target - target\n",
        "        std - \"standard_error\" from data ori\n",
        "    \"\"\"\n",
        "    def __init__(self, df, tokenizer, cfg, transforms=None):\n",
        "        self.df = df.reset_index()\n",
        "        self.augmentations = transforms\n",
        "        self.cfg = cfg\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.df.iloc[index]\n",
        "\n",
        "        text_original = row[\"excerpt\"]\n",
        "\n",
        "        text = self.tokenizer(text_original,\n",
        "                              padding=\"max_length\",\n",
        "                              max_length=self.cfg.max_length,\n",
        "                              truncation=True,\n",
        "                              return_tensors=\"pt\",\n",
        "                              return_token_type_ids=True)\n",
        "        input_ids = text[\"input_ids\"][0].detach().cpu().numpy()\n",
        "        input_ids_masked = [x if np.random.random() > self.cfg.mask_p else self.tokenizer.mask_token_id for x in input_ids]\n",
        "        input_ids_masked = torch.LongTensor(input_ids_masked).to(\"cuda\")\n",
        "        attention_mask = text[\"attention_mask\"][0]\n",
        "        token_type_ids = text[\"token_type_ids\"][0]\n",
        "        std = row[\"standard_error\"]\n",
        "\n",
        "        features = ((row[self.cfg.feature_columns].fillna(0).values - self.cfg.feature_mean) / self.cfg.feature_std)\n",
        "        \"\"\"\n",
        "        take currnet (row and - mean(all)) / std(all)\n",
        "        array([ 0.13797008, -0.14786123,  0.17155507,  0.24627862,  0.14901487,\n",
        "                0.21311318,  0.08742476,  0.26920065, -0.39593219, -0.3817358 ,\n",
        "               -0.38798113, -0.38889757, -0.63937729, -0.57226923, -0.66869829,\n",
        "                0.4939904 ,  0.48264299])                \n",
        "        \"\"\"\n",
        "        features = torch.tensor(features, dtype=torch.float)\n",
        "        target = torch.tensor(row[\"target\"], dtype=torch.float)\n",
        "        return input_ids_masked, attention_mask, token_type_ids, input_ids, features, target, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZMPNznZZow-"
      },
      "source": [
        "## Module&Heads, Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3b5fInuaJ42"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.core.lightning import LightningModule\n",
        "from pytorch_lightning.utilities import rank_zero_warn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyNig193Zw1I"
      },
      "source": [
        "import gc\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "# Applies weight normalization to a parameter in the given module.\n",
        "from torch.nn.utils import weight_norm\n",
        "\"\"\"\n",
        "https://github.com/rwightman/pytorch-image-models#introduction\n",
        "\n",
        "Модели изображений PyTorch (timm) - это набор моделей изображений, слоев, утилит, оптимизаторов,\n",
        "планировщиков, загрузчиков / дополнений данных и эталонных сценариев обучения / проверки, которые\n",
        "призваны объединить широкий спектр моделей SOTA с возможностью воспроизведения обучения ImageNet.\n",
        "полученные результаты.\n",
        "\"\"\"\n",
        "import timm\n",
        "try:\n",
        "    import mlflow.pytorch\n",
        "except Exception as e:\n",
        "    print(\"error: mlflow is not found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3awfO1GRQvp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-MpP6dLRQtf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUTi3E9hRQro"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLTPhfBmRQo3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}