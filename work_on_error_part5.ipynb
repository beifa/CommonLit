{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "work_on_error_part5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1a6UGXE4hEH73I7Yd7ayKU3yf_eCyD_xv",
      "authorship_tag": "ABX9TyPHDQKcTfAOguu0dqQnaEZi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgudlyKuktQ-"
      },
      "source": [
        "TODO\n",
        "\n",
        "[kaggle 22 place solution]('https://www.kaggle.com/c/commonlitreadabilityprize/discussion/257302)\n",
        "\n",
        "[github]('https://github.com/kurupical/commonlit)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjh2wZULST-c"
      },
      "source": [
        "configuration for almost all models:\n",
        "```\n",
        "epochs = 4\n",
        "optimizer: AdamW\n",
        "scheduler: linear_schedule_with_warmup(warmup: 5%)\n",
        "lr_bert: 3e-5\n",
        "batch_size: 12\n",
        "gradient clipping: 0.2~0.5\n",
        "reinitialize layers: last 2~6 layers\n",
        "ensemble: Nelder-Mead\n",
        "custom head(finally concat all)\n",
        "    averaging last 4 hidden layer\n",
        "    LSTM head\n",
        "    vocabulary dense\n",
        "hidden_states: (batch_size, vocab_size, bert_hidden_size)\n",
        "  linear_vocab = nn.Sequential(\n",
        "      nn.Linear(bert_hidden_size, 128),\n",
        "      nn.GELU(),\n",
        "      nn.Linear(128, 64),\n",
        "      nn.GELU()\n",
        "  )\n",
        "  linear_final = nn.Linear(vocab_size * 64, 128)\n",
        "  out = linear_vocab(hidden_states).view(len(input_ids), -1)) # final shape: (batch_size, vocab_size * 64)\n",
        "  out = linear_final(out) # out shape: (batch_size, 128)\n",
        "17 hand-made features\n",
        "    sentence count\n",
        "    average character count in documents\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh4W8bL9H1NZ"
      },
      "source": [
        "from IPython.display import clear_output, Image\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3XwACKoH1Na"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import itertools\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from numpy import random\n",
        "from torch import nn, optim\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "\"\"\"\n",
        "получения информации о запущенных процессах\n",
        "и использовании системы (ЦП, память, диски, сеть, датчики) в Python.\n",
        "\"\"\"\n",
        "import psutil\n",
        "\n",
        "path_tr = '/content/drive/MyDrive/CommonLit/input/train.csv'\n",
        "path_test = '/content/drive/MyDrive/CommonLit/input/test.csv'\n",
        "path_sub = '/content/drive/MyDrive/CommonLit/input/sample_submission.csv'\n",
        "\n",
        "SEED =13\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siMBoJn2Rwvn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTrjgerCRws9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}