{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basline_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Qh6cVMR7m27dXJo-1VMxoWiEqQU4Hq68",
      "authorship_tag": "ABX9TyOM2Rz9UW3zKnmT/cYijrZA"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KsrTcKtZTwC"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "TJZ_KqlNZcqQ",
        "outputId": "874fe837-0959-4247-eb4a-10c7f535d167"
      },
      "source": [
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import  DataLoader, Dataset\n",
        "import transformers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "path_tr = '/content/drive/MyDrive/CommonLit/input/train.csv'\n",
        "path_test = '/content/drive/MyDrive/CommonLit/input/test.csv'\n",
        "path_sub = '/content/drive/MyDrive/CommonLit/input/sample_submission.csv'\n",
        "\n",
        "df = pd.read_csv(path_tr)\n",
        "\n",
        "SEED =13\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def clean_text(txt):\n",
        "    return re.sub('[^A-Za-z]+', ' ',str(txt).lower())\n",
        "df['txt'] = df['excerpt'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df.head(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "      <th>txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "      <td>when the young people returned to the ballroom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "      <td>all through dinner time mrs fayre was somewhat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                                txt\n",
              "0  c12129c31  ...  when the young people returned to the ballroom...\n",
              "1  85aa80a4c  ...  all through dinner time mrs fayre was somewhat...\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TrBVs4DZveO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2h9W_fyZhRG"
      },
      "source": [
        "class CL_Dataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        max_len: int = 255,\n",
        "        test: bool = False\n",
        "        ) -> dict:\n",
        "        self.data = data \n",
        "        self.max_len = max_len\n",
        "        self.test = test\n",
        "        self.token = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def  __getitem__(self, idx: int):\n",
        "        text = self.data.txt.iloc[idx]\n",
        "        encode = self.token.encode_plus(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            add_special_tokens=True,            \n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt'\n",
        "            )\n",
        "        if self.test:\n",
        "            target = 0\n",
        "        else:\n",
        "            target = self.data.target.iloc[idx]                    \n",
        "        return {\n",
        "                'input_ids': encode['input_ids'],\n",
        "                'attention_mask': encode['attention_mask'],\n",
        "                'target': torch.tensor(target, dtype = torch.float)  \n",
        "                }\n",
        "\n",
        "class CL_model(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_out:int = 1):\n",
        "        super(CL_model, self).__init__()\n",
        "        self.dim_out = dim_out\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop = nn.Dropout(p = 0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, self.dim_out)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out_model = self.bert(input_ids, attention_mask)\n",
        "        d1 = self.drop(out_model['pooler_output'])\n",
        "        out = self.out(d1)\n",
        "        return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFTGY6cBagJZ"
      },
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))\n",
        "\n",
        "\n",
        "def train(\n",
        "    model:nn.Module, \n",
        "    loader: DataLoader,\n",
        "    optimizer: transformers.AdamW,\n",
        "    schedule: transformers.get_linear_schedule_with_warmup,\n",
        "    batch: int,\n",
        "    max_lenght: int\n",
        ") -> list:\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    all_pred, all_target, losses = [], [], []\n",
        "    for input in loader:\n",
        "        optimizer.zero_grad()\n",
        "        ii = input['input_ids'].squeeze().to(device) # view(batch, max_lenght).to(device)\n",
        "        am = input['attention_mask'].squeeze().to(device) # .view(batch, max_lenght).to(device)\n",
        "        target = input['target'].to(device)\n",
        "        out = model(input_ids =ii, attention_mask = am)\n",
        "        loss = loss_fn(out.squeeze(-1), target)\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        all_pred.append(out.squeeze(-1).detach().cpu().numpy())\n",
        "        all_target.append(target.detach().cpu().numpy())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "        optimizer.step()    \n",
        "        schedule.step()\n",
        "    losses = np.mean(losses)\n",
        "    allt = np.concatenate(all_target)\n",
        "    allp = np.concatenate(all_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(allt, allp))  \n",
        "    return losses, rmse\n",
        "\n",
        "\n",
        "def validate(\n",
        "    model:nn.Module, \n",
        "    loader: DataLoader, \n",
        "    batch: int,\n",
        "    max_lenght: int\n",
        ") -> list:\n",
        "    model.eval()\n",
        "    all_pred, all_target, losses = [], [], []\n",
        "    for input in loader:\n",
        "        ii = input['input_ids'].squeeze().to(device) # view(batch, max_lenght).to(device)\n",
        "        am = input['attention_mask'].squeeze().to(device) # .view(batch, max_lenght).to(device)\n",
        "        target = input['target'].to(device)\n",
        "        out = model(input_ids =ii, attention_mask = am)\n",
        "        loss = loss_fn(out.squeeze(-1), target)\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        all_pred.append(out.squeeze(-1).detach().cpu().numpy())\n",
        "        all_target.append(target.detach().cpu().numpy())  \n",
        "    losses = np.mean(losses)\n",
        "    allt = np.concatenate(all_target)\n",
        "    allp = np.concatenate(all_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(allt, allp)) \n",
        "    return losses, rmse\n",
        "\n",
        "\n",
        "def showtime(model:nn.Module, data: pd.DataFrame):\n",
        "    \n",
        "    model = model.to(device)\n",
        "    X_train, X_test = train_test_split(\n",
        "        data,\n",
        "        test_size=0.2,\n",
        "        random_state=SEED\n",
        "    )# ((2267, 6), (567, 6))\n",
        "    tr = CL_Dataset(X_train, MAX_LEN)\n",
        "    vl = CL_Dataset(X_test,  MAX_LEN)\n",
        "    tr_loader = DataLoader(\n",
        "        tr,\n",
        "        batch_size=BATCH,\n",
        "        shuffle=True\n",
        "    )\n",
        "    vl_loader = DataLoader(\n",
        "        vl,\n",
        "        batch_size=BATCH,\n",
        "        shuffle=False\n",
        "    )\n",
        "    optimizer = transformers.AdamW(model.parameters(), lr=2e-5, correct_bias=True)\n",
        "    steps = len(tr_loader) * EPOCH\n",
        "    lin_schedule = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=1,\n",
        "        num_training_steps=steps\n",
        "    )\n",
        "    fold = 0\n",
        "    best_rmse = 100\n",
        "    for epoch in tqdm(range(EPOCH)):\n",
        "        tr_loss, tr_rmse = train(model, tr_loader, optimizer, lin_schedule, BATCH, MAX_LEN)\n",
        "        vl_loss, vl_rmse = validate(model, vl_loader, BATCH, MAX_LEN)\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        print(f'Epoch: {epoch}, lr: {lr}, train rmse: {tr_rmse}, vl rmse: {vl_rmse}, vl loss: {vl_loss}')\n",
        "        if vl_rmse < best_rmse:\n",
        "            print(f'Save rmse: {vl_rmse}')\n",
        "            torch.save(model.state_dict(), f'{MODEL}_model_{fold}_{vl_rmse}.pth')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pxC2vLvfohS",
        "outputId": "1a57dbe2-4bbf-42cf-ca33-383f4c2e9093"
      },
      "source": [
        "EPOCH = 10\n",
        "BATCH = 8\n",
        "MAX_LEN = 314#, 255\n",
        "model = CL_model()\n",
        "MODEL = model.__class__.__name__\n",
        "showtime(model, df)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, lr: 1.8006340260655162e-05, train rmse: 0.7601271867752075, vl rmse: 0.5724765658378601, vl loss: 0.5519900918006897\n",
            "Save rmse: 0.5724765658378601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [02:36<23:32, 157.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, lr: 1.6005635787249034e-05, train rmse: 0.5292499661445618, vl rmse: 0.5428774356842041, vl loss: 0.5211071372032166\n",
            "Save rmse: 0.5428774356842041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [05:21<21:12, 159.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2, lr: 1.4004931313842904e-05, train rmse: 0.41651758551597595, vl rmse: 0.7206393480300903, vl loss: 0.7050365805625916\n",
            "Save rmse: 0.7206393480300903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [08:04<18:43, 160.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3, lr: 1.2004226840436775e-05, train rmse: 0.33295121788978577, vl rmse: 0.7406666278839111, vl loss: 0.7245230674743652\n",
            "Save rmse: 0.7406666278839111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [10:48<16:08, 161.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4, lr: 1.0003522367030645e-05, train rmse: 0.2692682147026062, vl rmse: 0.6737424731254578, vl loss: 0.6561287045478821\n",
            "Save rmse: 0.6737424731254578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [13:31<13:30, 162.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, lr: 8.002817893624517e-06, train rmse: 0.21980290114879608, vl rmse: 0.6019706726074219, vl loss: 0.5849028825759888\n",
            "Save rmse: 0.6019706726074219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [16:15<10:49, 162.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6, lr: 6.002113420218388e-06, train rmse: 0.18207767605781555, vl rmse: 0.6223962306976318, vl loss: 0.6051130294799805\n",
            "Save rmse: 0.6223962306976318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [18:58<08:08, 162.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7, lr: 4.001408946812258e-06, train rmse: 0.16161870956420898, vl rmse: 0.605218231678009, vl loss: 0.5864432454109192\n",
            "Save rmse: 0.605218231678009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [21:42<05:26, 163.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8, lr: 2.000704473406129e-06, train rmse: 0.1446959525346756, vl rmse: 0.608823299407959, vl loss: 0.5910805463790894\n",
            "Save rmse: 0.608823299407959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [24:25<02:43, 163.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9, lr: 0.0, train rmse: 0.1320406198501587, vl rmse: 0.606290340423584, vl loss: 0.5884116888046265\n",
            "Save rmse: 0.606290340423584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [27:09<00:00, 162.94s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utgS5obtLY72"
      },
      "source": [
        "#inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5EMQKbknWaO"
      },
      "source": [
        "import gc\n",
        "_ = gc.collect()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Llydl2YFpbHR",
        "outputId": "4830f9ab-3f84-4210-bbb9-45ce314fbf1b"
      },
      "source": [
        "test = pd.read_csv(path_test)\n",
        "test.head(1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c0f722661</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            excerpt\n",
              "0  c0f722661  ...  My hope lay in Jack's promise that he would ke...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXPO1Cb_pgc9",
        "outputId": "046e8dc1-e1e0-487b-8fa6-21691bc7c4e3"
      },
      "source": [
        "@torch.no_grad()\n",
        "def inference(model:nn.Module, data: pd.DataFrame):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    test = CL_Dataset(data, MAX_LEN, True)\n",
        "    test_loader = DataLoader(\n",
        "        test,\n",
        "        batch_size=1,\n",
        "        shuffle=False\n",
        "    )\n",
        "    all_pred = []\n",
        "    for input in tqdm(test_loader):\n",
        "        ii = input['input_ids'].view(1, MAX_LEN).to(device)\n",
        "        am = input['attention_mask'].view(1, MAX_LEN).to(device)\n",
        "        out = model(input_ids =ii, attention_mask = am)\n",
        "        all_pred.append(out.squeeze(-1).detach().cpu().numpy())\n",
        "    return np.concatenate(all_pred)\n",
        "    \n",
        "\n",
        "model = CL_model()\n",
        "model.load_state_dict(torch.load('/content/CL_model_model_0_0.5428774356842041.pth'))\n",
        "def clean_text(txt):\n",
        "    return re.sub('[^A-Za-z]+', ' ',str(txt).lower())\n",
        "\n",
        "\n",
        "test['txt'] = test['excerpt'].apply(lambda x: clean_text(x))\n",
        "pred = inference(model, test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 7/7 [00:00<00:00, 27.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ5H8671pgjl",
        "outputId": "345cfa80-9c4b-43b1-f5eb-51b12360b542"
      },
      "source": [
        "pred"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.1042218 , -0.4232107 , -1.8214164 , -0.3670986 , -0.6991254 ,\n",
              "        0.61048067, -0.3709323 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHydG5rVLVdh"
      },
      "source": [
        "#save to load local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9eWB0vgKiU6",
        "outputId": "7cb9f8e4-1ba4-4df1-b47c-87da4c7b1828"
      },
      "source": [
        "# save token\n",
        "token = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "token.save_pretrained(\"./model_uncase_bert\")\n",
        "#save model\n",
        "bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "bert.save_pretrained(\"./model_uncase_bert\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8V3ylq0ZLj_"
      },
      "source": [
        "change max_length 314\n",
        "add token_type_ids\n",
        "change bert to clasifir\n",
        "change drop out\n",
        "change lr to"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}