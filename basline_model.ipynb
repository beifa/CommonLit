{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basline_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Qh6cVMR7m27dXJo-1VMxoWiEqQU4Hq68",
      "authorship_tag": "ABX9TyMCf1FDLL1LUSerRLgsza5d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KsrTcKtZTwC"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJZ_KqlNZcqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "44f12c10-3deb-4392-d7ed-16f793d05d6e"
      },
      "source": [
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import  DataLoader, Dataset\n",
        "import transformers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "path_tr = '/content/drive/MyDrive/CommonLit/input/train.csv'\n",
        "path_test = '/content/drive/MyDrive/CommonLit/input/test.csv'\n",
        "path_sub = '/content/drive/MyDrive/CommonLit/input/sample_submission.csv'\n",
        "\n",
        "df = pd.read_csv(path_tr)\n",
        "\n",
        "SEED =13\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def clean_text(txt):\n",
        "    return re.sub('[^A-Za-z]+', ' ',str(txt).lower())\n",
        "df['txt'] = df['excerpt'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df.head(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "      <th>txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "      <td>when the young people returned to the ballroom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "      <td>all through dinner time mrs fayre was somewhat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                                txt\n",
              "0  c12129c31  ...  when the young people returned to the ballroom...\n",
              "1  85aa80a4c  ...  all through dinner time mrs fayre was somewhat...\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TrBVs4DZveO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2h9W_fyZhRG"
      },
      "source": [
        "class CL_Dataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        max_len: int = 255,\n",
        "        test: bool = False\n",
        "        ) -> dict:\n",
        "        self.data = data \n",
        "        self.max_len = max_len\n",
        "        self.test = test\n",
        "        self.token = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def  __getitem__(self, idx: int):\n",
        "        text = self.data.txt.iloc[idx]\n",
        "        encode = self.token.encode_plus(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            add_special_tokens=True,            \n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False,\n",
        "            return_tensors='pt'\n",
        "            )\n",
        "        if self.test:\n",
        "            target = 0\n",
        "        else:\n",
        "            target = self.data.target.iloc[idx]                    \n",
        "        return {\n",
        "                'input_ids': encode['input_ids'],\n",
        "                'attention_mask': encode['attention_mask'],\n",
        "                'target': torch.tensor(target, dtype = torch.float)  \n",
        "                }\n",
        "\n",
        "class CL_model(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_out:int = 1):\n",
        "        super(CL_model, self).__init__()\n",
        "        self.dim_out = dim_out\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop = nn.Dropout(p = 0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, self.dim_out)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out_model = self.bert(input_ids, attention_mask)\n",
        "        d1 = self.drop(out_model['pooler_output'])\n",
        "        out = self.out(d1)\n",
        "        return out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFTGY6cBagJZ"
      },
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))\n",
        "\n",
        "\n",
        "def train(\n",
        "    model:nn.Module, \n",
        "    loader: DataLoader,\n",
        "    optimizer: transformers.AdamW,\n",
        "    schedule: transformers.get_linear_schedule_with_warmup,\n",
        "    batch: int,\n",
        "    max_lenght: int\n",
        ") -> list:\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    all_pred, all_target, losses = [], [], []\n",
        "    for input in tqdm(loader):\n",
        "        optimizer.zero_grad()\n",
        "        ii = input['input_ids'].squeeze().to(device) # view(batch, max_lenght).to(device)\n",
        "        am = input['attention_mask'].squeeze().to(device) # .view(batch, max_lenght).to(device)\n",
        "        target = input['target'].to(device)\n",
        "        out = model(input_ids =ii, attention_mask = am)\n",
        "        loss = loss_fn(out.squeeze(-1), target)\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        all_pred.append(out.squeeze(-1).detach().cpu().numpy())\n",
        "        all_target.append(target.detach().cpu().numpy())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "        optimizer.step()    \n",
        "        schedule.step()\n",
        "    losses = np.mean(losses)\n",
        "    allt = np.concatenate(all_target)\n",
        "    allp = np.concatenate(all_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(allt, allp))  \n",
        "    return losses, rmse\n",
        "\n",
        "\n",
        "def validate(\n",
        "    model:nn.Module, \n",
        "    loader: DataLoader, \n",
        "    batch: int,\n",
        "    max_lenght: int\n",
        ") -> list:\n",
        "    model.eval()\n",
        "    all_pred, all_target, losses = [], [], []\n",
        "    for input in tqdm(loader):\n",
        "        ii = input['input_ids'].squeeze().to(device) # view(batch, max_lenght).to(device)\n",
        "        am = input['attention_mask'].squeeze().to(device) # .view(batch, max_lenght).to(device)\n",
        "        target = input['target'].to(device)\n",
        "        out = model(input_ids =ii, attention_mask = am)\n",
        "        loss = loss_fn(out.squeeze(-1), target)\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        all_pred.append(out.squeeze(-1).detach().cpu().numpy())\n",
        "        all_target.append(target.detach().cpu().numpy())  \n",
        "    losses = np.mean(losses)\n",
        "    allt = np.concatenate(all_target)\n",
        "    allp = np.concatenate(all_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(allt, allp)) \n",
        "    return losses, rmse\n",
        "\n",
        "\n",
        "def showtime(model:nn.Module, data: pd.DataFrame):\n",
        "    \n",
        "    model = model.to(device)\n",
        "    X_train, X_test = train_test_split(\n",
        "        data.head(24),\n",
        "        test_size=0.2,\n",
        "        random_state=SEED\n",
        "    )# ((2267, 6), (567, 6))\n",
        "    tr = CL_Dataset(X_train, MAX_LEN)\n",
        "    vl = CL_Dataset(X_test,  MAX_LEN)\n",
        "    tr_loader = DataLoader(\n",
        "        tr,\n",
        "        batch_size=BATCH,\n",
        "        shuffle=True\n",
        "    )\n",
        "    vl_loader = DataLoader(\n",
        "        vl,\n",
        "        batch_size=BATCH,\n",
        "        shuffle=False\n",
        "    )\n",
        "    optimizer = transformers.AdamW(model.parameters(), lr=2e-5, correct_bias=True)\n",
        "    steps = len(tr_loader) * EPOCH\n",
        "    lin_schedule = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=1,\n",
        "        num_training_steps=steps\n",
        "    )\n",
        "    fold = 0\n",
        "    best_rmse = 100\n",
        "    for epoch in tqdm(range(EPOCH)):\n",
        "        tr_loss, tr_rmse = train(model, tr_loader, optimizer, lin_schedule, BATCH, MAX_LEN)\n",
        "        vl_loss, vl_rmse = validate(model, vl_loader, BATCH, MAX_LEN)\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        print(f'Epoch: {epoch}, lr: {lr}, train rmse: {tr_rmse}, vl rmse: {vl_rmse}, vl loss: {vl_loss}')\n",
        "        if vl_rmse < best_rmse:\n",
        "            print(f'Save rmse: {vl_rmse}')\n",
        "            torch.save(model.state_dict(), f'{MODEL}_model_{fold}_{vl_rmse}.pth')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pxC2vLvfohS",
        "outputId": "c6f69116-a21c-43b2-f4c5-e0b755ddb1ff"
      },
      "source": [
        "EPOCH = 10\n",
        "BATCH = 8\n",
        "MAX_LEN = 255\n",
        "model = CL_model()\n",
        "MODEL = model.__class__.__name__\n",
        "showtime(model, df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.07it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.11it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.65it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, lr: 1.8620689655172415e-05, train rmse: 1.2684041261672974, vl rmse: 0.7171961665153503, vl loss: 0.7171961665153503\n",
            "Save rmse: 0.7171961665153503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:02<00:22,  2.55s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.25it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.20it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.68it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00, 10.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, lr: 1.6551724137931037e-05, train rmse: 0.9221476912498474, vl rmse: 0.7022027373313904, vl loss: 0.7022027373313904\n",
            "Save rmse: 0.7022027373313904\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [00:04<00:20,  2.51s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.16it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.14it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.63it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00, 10.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2, lr: 1.4482758620689657e-05, train rmse: 0.9372828602790833, vl rmse: 0.7080178260803223, vl loss: 0.7080178260803223\n",
            "Save rmse: 0.7080178260803223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 3/10 [00:07<00:17,  2.51s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.18it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.15it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.63it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00, 10.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3, lr: 1.2413793103448277e-05, train rmse: 0.8971720933914185, vl rmse: 0.6894130706787109, vl loss: 0.6894130110740662\n",
            "Save rmse: 0.6894130706787109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [00:12<00:18,  3.14s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.03it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.10it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.63it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00, 10.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4, lr: 1.0344827586206898e-05, train rmse: 0.9165782928466797, vl rmse: 0.6776334643363953, vl loss: 0.6776334643363953\n",
            "Save rmse: 0.6776334643363953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [00:23<00:27,  5.56s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.00it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.05it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.58it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00, 10.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5, lr: 8.275862068965518e-06, train rmse: 0.9626761078834534, vl rmse: 0.670048713684082, vl loss: 0.6700486540794373\n",
            "Save rmse: 0.670048713684082\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6/10 [00:34<00:28,  7.16s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.02it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.08it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.62it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00,  9.00it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6, lr: 6.206896551724138e-06, train rmse: 0.9040706753730774, vl rmse: 0.6629596948623657, vl loss: 0.6629596948623657\n",
            "Save rmse: 0.6629596948623657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7/10 [00:46<00:26,  8.70s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.05it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.10it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.64it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00, 10.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7, lr: 4.137931034482759e-06, train rmse: 0.8878311514854431, vl rmse: 0.6576987504959106, vl loss: 0.6576987504959106\n",
            "Save rmse: 0.6576987504959106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [00:56<00:18,  9.16s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:01,  1.97it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.03it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.58it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8, lr: 2.0689655172413796e-06, train rmse: 0.8991280794143677, vl rmse: 0.6550197005271912, vl loss: 0.6550197005271912\n",
            "Save rmse: 0.6550197005271912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [01:07<00:09,  9.69s/it]\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 1/3 [00:00<00:00,  2.06it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 2/3 [00:00<00:00,  2.09it/s]\u001b[A\n",
            "100%|██████████| 3/3 [00:01<00:00,  2.61it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:00<00:00, 10.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9, lr: 0.0, train rmse: 0.8459253311157227, vl rmse: 0.6537800431251526, vl loss: 0.6537800431251526\n",
            "Save rmse: 0.6537800431251526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:20<00:00,  8.01s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5EMQKbknWaO"
      },
      "source": [
        "import gc\n",
        "# del method not need\n",
        "_ = gc.collect()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Llydl2YFpbHR",
        "outputId": "c7d110eb-2774-4d29-891d-56e2216f6dd2"
      },
      "source": [
        "test = pd.read_csv(path_test)\n",
        "test.head(1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c0f722661</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                            excerpt\n",
              "0  c0f722661  ...  My hope lay in Jack's promise that he would ke...\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXPO1Cb_pgc9",
        "outputId": "1521f970-cea3-4794-8409-8c13b5b5d6a6"
      },
      "source": [
        "@torch.no_grad()\n",
        "def inference(model:nn.Module, data: pd.DataFrame):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    test = CL_Dataset(data, MAX_LEN, True)\n",
        "    test_loader = DataLoader(\n",
        "        test,\n",
        "        batch_size=1,\n",
        "        shuffle=True\n",
        "    )\n",
        "    all_pred = []\n",
        "    for input in tqdm(test_loader):\n",
        "        ii = input['input_ids'].view(1, 255).to(device)\n",
        "        am = input['attention_mask'].view(1, 255).to(device)\n",
        "        out = model(input_ids =ii, attention_mask = am)\n",
        "        all_pred.append(out.squeeze(-1).detach().cpu().numpy())\n",
        "    return np.concatenate(all_pred)\n",
        "    \n",
        "\n",
        "model = CL_model()\n",
        "model.load_state_dict(torch.load('/content/CL_model_model_0_0.6537800431251526.pth'))\n",
        "def clean_text(txt):\n",
        "    return re.sub('[^A-Za-z]+', ' ',str(txt).lower())\n",
        "\n",
        "\n",
        "test['txt'] = test['excerpt'].apply(lambda x: clean_text(x))\n",
        "pred = inference(model, test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 3/7 [00:00<00:00, 26.00it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 255])\n",
            "torch.Size([1, 255])\n",
            "torch.Size([1, 255])\n",
            "torch.Size([1, 255])\n",
            "torch.Size([1, 255])\n",
            "torch.Size([1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 7/7 [00:00<00:00, 27.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 255])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ5H8671pgjl",
        "outputId": "a677c38c-3451-43ee-9418-1ebf0af7b397"
      },
      "source": [
        "pred"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.83763963, -0.77272505, -0.75076175, -0.8542761 , -0.87986195,\n",
              "       -0.7421036 , -0.85180527], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}