{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Qh6cVMR7m27dXJo-1VMxoWiEqQU4Hq68",
      "authorship_tag": "ABX9TyMCT2gAEOiGKxFfo8YCojUi"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KsrTcKtZTwC"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "TJZ_KqlNZcqQ",
        "outputId": "97a857c5-3db9-41c3-b589-f4212b5e6f23"
      },
      "source": [
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import  DataLoader, Dataset\n",
        "import transformers\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "path_tr = '/content/drive/MyDrive/CommonLit/input/train.csv'\n",
        "path_test = '/content/drive/MyDrive/CommonLit/input/test.csv'\n",
        "path_sub = '/content/drive/MyDrive/CommonLit/input/sample_submission.csv'\n",
        "\n",
        "df = pd.read_csv(path_tr)\n",
        "\n",
        "SEED =13\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def clean_text(txt):\n",
        "    return re.sub('[^A-Za-z]+', ' ',str(txt).lower())\n",
        "df['txt'] = df['excerpt'].apply(lambda x: clean_text(x))\n",
        "\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>url_legal</th>\n",
              "      <th>license</th>\n",
              "      <th>excerpt</th>\n",
              "      <th>target</th>\n",
              "      <th>standard_error</th>\n",
              "      <th>txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c12129c31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When the young people returned to the ballroom...</td>\n",
              "      <td>-0.340259</td>\n",
              "      <td>0.464009</td>\n",
              "      <td>when the young people returned to the ballroom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>85aa80a4c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
              "      <td>-0.315372</td>\n",
              "      <td>0.480805</td>\n",
              "      <td>all through dinner time mrs fayre was somewhat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                                txt\n",
              "0  c12129c31  ...  when the young people returned to the ballroom...\n",
              "1  85aa80a4c  ...  all through dinner time mrs fayre was somewhat...\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdWoOlsuHlhK"
      },
      "source": [
        "def make_folds(data: pd.DataFrame, split: int = 5):\n",
        "    data['kfold'] = -1\n",
        "    data = data.sample(frac =1).reset_index(drop=True)\n",
        "    num_bins = int(np.floor(1 + np.log2(len(data))))\n",
        "    data.loc[:, 'bins'] = pd.cut(\n",
        "        data['target'], bins = num_bins, labels = False\n",
        "    )\n",
        "    kf = model_selection.StratifiedKFold(n_splits=split)\n",
        "    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n",
        "        data.loc[v_, 'kfold'] = f\n",
        "    data = data.drop(\"bins\", axis=1)\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6piK6x8sHtQU",
        "outputId": "38bfcabb-6dd4-4c6c-e484-eb621c7c90e1"
      },
      "source": [
        "df_folds = make_folds(df, 5)\n",
        "df_folds.kfold.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    567\n",
              "1    567\n",
              "2    567\n",
              "0    567\n",
              "4    566\n",
              "Name: kfold, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2h9W_fyZhRG"
      },
      "source": [
        "class CL_Dataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        token,\n",
        "        max_len: int = 256,\n",
        "        test: bool = False\n",
        "        ) -> dict:\n",
        "        self.data = data \n",
        "        self.max_len = max_len\n",
        "        self.test = test\n",
        "        self.token = token\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def  __getitem__(self, idx: int):\n",
        "        text = self.data.txt.iloc[idx]\n",
        "        encode = self.token(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            add_special_tokens=True,            \n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=False  \n",
        "            )\n",
        "        if self.test:\n",
        "            target = 0\n",
        "        else:\n",
        "            target = self.data.target.iloc[idx]\n",
        "\n",
        "        ids = encode[\"input_ids\"]\n",
        "        mask = encode[\"attention_mask\"]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            'target': torch.tensor(target, dtype = torch.float)  \n",
        "        }\n",
        "\n",
        "\n",
        "class CL_model(nn.Module):\n",
        "\n",
        "    def __init__(self, dim_out:int = 1):\n",
        "        super(CL_model, self).__init__()\n",
        "        self.dim_out = dim_out\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.drop = nn.Dropout(p = 0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, self.dim_out)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        out_model = self.bert(input_ids, attention_mask)\n",
        "        d1 = self.drop(out_model['pooler_output'])\n",
        "        out = self.out(d1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFTGY6cBagJZ"
      },
      "source": [
        "def loss_fn(output,target):\n",
        "    return torch.sqrt(nn.MSELoss()(output,target))\n",
        "\n",
        "\n",
        "def viz_curve(data: dict, title: str) -> None:\n",
        "    epochs = list(range(1, EPOCH + 1))\n",
        "    fig = make_subplots(\n",
        "        rows=2, cols=2,\n",
        "        specs=[\n",
        "               [{\"colspan\": 2}, None],\n",
        "               [{}, {}],\n",
        "               ],\n",
        "               vertical_spacing=0.09,\n",
        "               subplot_titles=('Loss Curve',  'RMSE', 'LR')\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=epochs,\n",
        "            y=data['train_loss'],\n",
        "            mode='lines+markers',\n",
        "            name='Train Loss'),\n",
        "            row=1, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=epochs,\n",
        "            y=data['valid_loss'],\n",
        "            mode='lines+markers',\n",
        "            name='Valid Loss'),\n",
        "            row=1, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=epochs,\n",
        "            y=data['valid_rms'],\n",
        "            mode='lines+markers',\n",
        "            name='RMSE'),     \n",
        "            row=2, col=1\n",
        "    )\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=epochs,\n",
        "            y=data['lr'],\n",
        "            mode='lines+markers',\n",
        "            name='LR'), \n",
        "            row=2, col=2\n",
        "    )\n",
        "    fig.update_layout(\n",
        "        height=600,\n",
        "        width=600,\n",
        "        showlegend=False,\n",
        "        title = title,\n",
        "        margin=dict(l=10, r=10, t=30, b=20),                     \n",
        "        template=\"plotly_dark\"    \n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def update_result(\n",
        "    data: dict,\n",
        "    predict: torch.tensor,\n",
        "    target:torch.tensor\n",
        ") -> None:\n",
        "    loss = loss_fn(predict.squeeze(-1), target)\n",
        "    data['losses'].append(loss.detach().cpu().numpy())\n",
        "    data['all_pred'].append(predict.squeeze(-1).detach().cpu().numpy())\n",
        "    data['all_target'].append(target.detach().cpu().numpy())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def train(\n",
        "    model:nn.Module, \n",
        "    loader: DataLoader,\n",
        "    optimizer: transformers.AdamW,\n",
        "    schedule: transformers.get_linear_schedule_with_warmup,\n",
        "    batch: int,\n",
        "    max_lenght: int\n",
        ") -> list:\n",
        "    model.train()\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    results = defaultdict(list)\n",
        "    for input in loader:\n",
        "        optimizer.zero_grad()\n",
        "        target = input['target'].to(device)\n",
        "        batch = {k:v.to(device) for k,v in input.items() if k != 'target'}   \n",
        "        out = model(**batch)\n",
        "        # out = out.logits # BertForSequenceClassification\n",
        "        loss = update_result(results, out, target)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "        optimizer.step()    \n",
        "        schedule.step()\n",
        "    losses = np.mean(results['losses'])\n",
        "    allt = np.concatenate(results['all_target'])\n",
        "    allp = np.concatenate(results['all_pred'])\n",
        "    rmse = np.sqrt(mean_squared_error(allt, allp))  \n",
        "    return losses, rmse\n",
        "\n",
        "\n",
        "def validate(\n",
        "    model:nn.Module, \n",
        "    loader: DataLoader, \n",
        "    batch: int,\n",
        "    max_lenght: int\n",
        ") -> list:\n",
        "    model.eval()\n",
        "    results = defaultdict(list)\n",
        "    for input in loader:  \n",
        "        target = input['target'].to(device)\n",
        "        batch = {k:v.to(device) for k,v in input.items() if k != 'target'} \n",
        "        out = model(**batch)\n",
        "        # out = out.logits # BertForSequenceClassification\n",
        "        _ = update_result(results, out, target)\n",
        "    losses = np.mean(results['losses'])\n",
        "    allt = np.concatenate(results['all_target'])\n",
        "    allp = np.concatenate(results['all_pred'])\n",
        "    rmse = np.sqrt(mean_squared_error(allt, allp)) \n",
        "    return losses, rmse\n",
        "\n",
        "\n",
        "def showtime(model:nn.Module, data: pd.DataFrame, tokenizer:transformers.AutoTokenizer, fold: int) -> dict:    \n",
        "    history = defaultdict(list)\n",
        "    model = model.to(device)\n",
        "    ttr = data[data.kfold != fold].reset_index(drop=True)\n",
        "    vvl = data[data.kfold == fold].reset_index(drop=True)\n",
        "    print(f'Fold: {fold + 1}, --- {ttr.shape, vvl.shape}')\n",
        "\n",
        "    tr = CL_Dataset(ttr, tokenizer, MAX_LEN)\n",
        "    vl = CL_Dataset(vvl, tokenizer, MAX_LEN)\n",
        "    tr_loader = DataLoader(\n",
        "        tr,\n",
        "        batch_size=BATCH,\n",
        "        shuffle=True\n",
        "    )\n",
        "    vl_loader = DataLoader(\n",
        "        vl,\n",
        "        batch_size=BATCH,\n",
        "        shuffle=False\n",
        "    )\n",
        "    optimizer = transformers.AdamW(model.parameters(), lr=2e-5, correct_bias=True)\n",
        "    steps = len(tr_loader) * EPOCH\n",
        "    # steps = len(tr_loader)/BATCH * EPOCH\n",
        "    lin_schedule = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=1,\n",
        "        num_training_steps=steps\n",
        "    )\n",
        "    best_rmse = np.inf\n",
        "    for epoch in tqdm(range(EPOCH)):\n",
        "        tr_loss, tr_rmse = train(model, tr_loader, optimizer, lin_schedule, BATCH, MAX_LEN)\n",
        "        vl_loss, vl_rmse = validate(model, vl_loader, BATCH, MAX_LEN)\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "        history['train_loss'].append(tr_loss)\n",
        "        history['valid_loss'].append(vl_loss)\n",
        "        history['valid_rms'].append(vl_rmse)\n",
        "        history['lr'].append(lr)\n",
        "        print(f'Epoch: {epoch}, lr: {lr}, train rmse: {tr_rmse}, vl rmse: {vl_rmse}, vl loss: {vl_loss}')\n",
        "        if vl_rmse < best_rmse:\n",
        "            print(f'Save rmse: {vl_rmse}')\n",
        "            torch.save(model.state_dict(), f'{MODEL}_model_{fold}.pth')\n",
        "            best_rmse = vl_rmse\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "7pxC2vLvfohS",
        "outputId": "7f552500-a544-4542-c2f3-ec2658ea2de8"
      },
      "source": [
        "EPOCH = 1\n",
        "BATCH = 8\n",
        "MAX_LEN = 314\n",
        "model = CL_model()\n",
        "# model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
        "MODEL = model.__class__.__name__\n",
        "fold = 0\n",
        "title = f'Fold: {fold + 1}'\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "history = showtime(model, df_folds, tokenizer, fold)\n",
        "viz_curve(history, title)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold: 1, --- ((2267, 8), (567, 8))\n",
            "Epoch: 0, lr: 0.0, train rmse: 0.7412992715835571, vl rmse: 0.6628739833831787, vl loss: 0.6422673463821411\n",
            "Save rmse: 0.6628739833831787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [02:29<00:00, 149.27s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"023d16af-b64e-4ba8-bff9-7a4d6ee5b5cb\" class=\"plotly-graph-div\" style=\"height:600px; width:600px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"023d16af-b64e-4ba8-bff9-7a4d6ee5b5cb\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '023d16af-b64e-4ba8-bff9-7a4d6ee5b5cb',\n",
              "                        [{\"mode\": \"lines+markers\", \"name\": \"Train Loss\", \"type\": \"scatter\", \"x\": [1], \"xaxis\": \"x\", \"y\": [0.7033988833427429], \"yaxis\": \"y\"}, {\"mode\": \"lines+markers\", \"name\": \"Valid Loss\", \"type\": \"scatter\", \"x\": [1], \"xaxis\": \"x\", \"y\": [0.6422673463821411], \"yaxis\": \"y\"}, {\"mode\": \"lines+markers\", \"name\": \"RMSE\", \"type\": \"scatter\", \"x\": [1], \"xaxis\": \"x2\", \"y\": [0.6628739833831787], \"yaxis\": \"y2\"}, {\"mode\": \"lines+markers\", \"name\": \"LR\", \"type\": \"scatter\", \"x\": [1], \"xaxis\": \"x3\", \"y\": [0.0], \"yaxis\": \"y3\"}],\n",
              "                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Loss Curve\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"RMSE\", \"x\": 0.225, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.455, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"LR\", \"x\": 0.775, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.455, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"margin\": {\"b\": 20, \"l\": 10, \"r\": 10, \"t\": 30}, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#f2f5fa\"}, \"error_y\": {\"color\": \"#f2f5fa\"}, \"marker\": {\"line\": {\"color\": \"rgb(17,17,17)\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"rgb(17,17,17)\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#A2B1C6\", \"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"minorgridcolor\": \"#506784\", \"startlinecolor\": \"#A2B1C6\"}, \"baxis\": {\"endlinecolor\": \"#A2B1C6\", \"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"minorgridcolor\": \"#506784\", \"startlinecolor\": \"#A2B1C6\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"line\": {\"color\": \"#283442\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"line\": {\"color\": \"#283442\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#506784\"}, \"line\": {\"color\": \"rgb(17,17,17)\"}}, \"header\": {\"fill\": {\"color\": \"#2a3f5f\"}, \"line\": {\"color\": \"rgb(17,17,17)\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#f2f5fa\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#f2f5fa\"}, \"geo\": {\"bgcolor\": \"rgb(17,17,17)\", \"lakecolor\": \"rgb(17,17,17)\", \"landcolor\": \"rgb(17,17,17)\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#506784\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"dark\"}, \"paper_bgcolor\": \"rgb(17,17,17)\", \"plot_bgcolor\": \"rgb(17,17,17)\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"bgcolor\": \"rgb(17,17,17)\", \"radialaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}, \"yaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}, \"zaxis\": {\"backgroundcolor\": \"rgb(17,17,17)\", \"gridcolor\": \"#506784\", \"gridwidth\": 2, \"linecolor\": \"#506784\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#C8D4E3\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#f2f5fa\"}}, \"sliderdefaults\": {\"bgcolor\": \"#C8D4E3\", \"bordercolor\": \"rgb(17,17,17)\", \"borderwidth\": 1, \"tickwidth\": 0}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}, \"bgcolor\": \"rgb(17,17,17)\", \"caxis\": {\"gridcolor\": \"#506784\", \"linecolor\": \"#506784\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"updatemenudefaults\": {\"bgcolor\": \"#506784\", \"borderwidth\": 0}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#283442\", \"linecolor\": \"#506784\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#283442\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#283442\", \"linecolor\": \"#506784\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#283442\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Fold: 1\"}, \"width\": 600, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0]}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.0, 0.45]}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.55, 1.0]}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.545, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.455]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 0.455]}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('023d16af-b64e-4ba8-bff9-7a4d6ee5b5cb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNGYHB2U_awV"
      },
      "source": [
        "stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utgS5obtLY72"
      },
      "source": [
        "#inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5EMQKbknWaO"
      },
      "source": [
        "import gc\n",
        "_ = gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Llydl2YFpbHR"
      },
      "source": [
        "test = pd.read_csv(path_test)\n",
        "test.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXPO1Cb_pgc9"
      },
      "source": [
        "@torch.no_grad()\n",
        "def inference(model:nn.Module, data: pd.DataFrame):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    test = CL_Dataset(data, MAX_LEN, True)\n",
        "    test_loader = DataLoader(\n",
        "        test,\n",
        "        batch_size=1,\n",
        "        shuffle=False\n",
        "    )\n",
        "    all_pred = []\n",
        "    for input in tqdm(test_loader):\n",
        "        ii = input['input_ids'].view(1, MAX_LEN).to(device)\n",
        "        am = input['attention_mask'].view(1, MAX_LEN).to(device)\n",
        "        out = model(input_ids =ii, attention_mask = am)\n",
        "        all_pred.append(out.squeeze(-1).detach().cpu().numpy())\n",
        "    return np.concatenate(all_pred)\n",
        "    \n",
        "\n",
        "model = CL_model()\n",
        "model.load_state_dict(torch.load('/content/CL_model_model_0_0.5428774356842041.pth'))\n",
        "def clean_text(txt):\n",
        "    return re.sub('[^A-Za-z]+', ' ',str(txt).lower())\n",
        "\n",
        "\n",
        "test['txt'] = test['excerpt'].apply(lambda x: clean_text(x))\n",
        "pred = inference(model, test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ5H8671pgjl"
      },
      "source": [
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHydG5rVLVdh"
      },
      "source": [
        "#save to load local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9eWB0vgKiU6"
      },
      "source": [
        "# save token\n",
        "token = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "token.save_pretrained(\"./model_uncase_bert\")\n",
        "#save model\n",
        "bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "bert.save_pretrained(\"./model_uncase_bert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuT0ne_9k16Y"
      },
      "source": [
        "model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
        "token = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "token.save_pretrained(\"./model_uncase_bert\")\n",
        "#save model\n",
        "model.save_pretrained(\"./model_uncase_bert\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dry3oHnOwGoo"
      },
      "source": [
        "# Experements\n",
        "EPOCH = 10, BATCH = 8\n",
        "\n",
        "- (?) clear_txt, max_length = 314 = score - 0.56\n",
        "- (best train 0.5789) clear_txt, max_length = 256 = score - 0.608\n",
        "- (best train 0.5466) clear_txt, max_length = 255 = score - 0.574\n",
        "- (best train 0.5595) clear_txt, max_length = 356  = score -0.583\n",
        "- (best train 0.5294) clear_txt, max_length = 314  = score -0.534\n",
        "- (best train 0.5572 ) clear_txt, max_length = 192  = score -0.582\n",
        "\n",
        "change bert to clasifir\n",
        "- (best train 0.5596) clear_txt, max_length = 255  = score -0.593\n",
        "\n",
        "autonlp\n",
        "- (best train 0.6111) clear_txt, max_length = 255  = score -0.605\n",
        "\n",
        "t5 -fast\n",
        "- (best train 0.6111) clear_txt, max_length = 255  = score -0.605\n",
        "\n",
        "batch up 8 --> 16\n",
        "- clear_txt, max_length= score=\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_2ESZ1JoQre"
      },
      "source": [
        "make auto nlp\n",
        "check score"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}